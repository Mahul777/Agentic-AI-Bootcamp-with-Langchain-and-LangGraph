{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "369bb6e2",
   "metadata": {},
   "source": [
    "### Chain Using LangGraph\n",
    "\n",
    "In this section we will see how we can build a simple chain using Langgraph that uses 4 important concepts\n",
    "\n",
    "* How to use **chat messages** as our graph state\n",
    "\n",
    "* How to use **chat models** in graph nodes\n",
    "\n",
    "* How to **bind tools** to our LLM in chat models\n",
    "\n",
    "* How to **execute the tools call** in our graph nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b33825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: LLM_Model\n",
      "\n",
      "Please tell me how can I help?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: Apoorv\n",
      "\n",
      "I want to learn coding\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: LLM_Model\n",
      "\n",
      "Which programming language do you want to learn?\n"
     ]
    }
   ],
   "source": [
    "# ‚úÖ Step 1: Set Up Environment\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "# os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")\n",
    "# üîπ This sets up your API keys so LLMs and tools can work.\n",
    "\n",
    "# ‚úÖ Step 2: Chat Messages as Graph State\n",
    "# ‚Ä¢\tüí¨ Use different message types to create a chat simulation:\n",
    "# o\tAIMessage, HumanMessage, etc.\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "from pprint import pprint\n",
    "# üîπ Create Messages Manually\n",
    "messages = []\n",
    "\n",
    "# ü§ñ AI Message\n",
    "messages.append(AIMessage(content=\"Please tell me how can I help?\", name=\"LLM_Model\"))\n",
    "\n",
    "# üßë‚Äçüíª Human Message\n",
    "messages.append(HumanMessage(content=\"I want to learn coding\", name=\"Apoorv\"))\n",
    "\n",
    "# ü§ñ AI Response Again\n",
    "messages.append(AIMessage(content=\"Which programming language do you want to learn?\", name=\"LLM_Model\"))\n",
    "# üîπ Print Messages Nicely\n",
    "for msg in messages:\n",
    "    msg.pretty_print()\n",
    "# ==================================\u001b[1m Ai Message \u001b[0m==================================\n",
    "# Name: LLM_Model\n",
    "\n",
    "# Please tell me how can I help?\n",
    "# ================================\u001b[1m Human Message \u001b[0m=================================\n",
    "# Name: Apoorv\n",
    "\n",
    "# I want to learn coding\n",
    "# ==================================\u001b[1m Ai Message \u001b[0m==================================\n",
    "# Name: LLM_Model\n",
    "\n",
    "# Which programming language do you want to learn?\n",
    "\n",
    "\n",
    "# üìå Output shows:\n",
    "# ‚Ä¢\tMessage type (AI/Human)\n",
    "# ‚Ä¢\tName (who said it)\n",
    "# ‚Ä¢\tMessage content\n",
    "# Looks like:\n",
    "# AI: Please tell me how can I help?\n",
    "# Human: I want to learn coding\n",
    "# AI: Which programming language do you want to learn?\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7439e167",
   "metadata": {},
   "source": [
    "### Chat Models\n",
    "\n",
    "We can use the sequence of message as input with the chatmodels using LLM's and OPENAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e34d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Python is a great language to learn. What do you want to do with Python? Do you want to:\\n\\n1. Build web applications?\\n2. Work with data science and machine learning?\\n3. Automate tasks?\\n4. Create games?\\n\\nKnowing your goals will help me provide more tailored guidance. \\n\\nAlso, are you a complete beginner or do you have some programming experience?' response_metadata={'token_usage': {'completion_tokens': 188, 'prompt_tokens': 409, 'total_tokens': 597, 'completion_time': 0.51895, 'prompt_time': 0.036868, 'queue_time': 0.135441, 'total_time': 0.555818}, 'model_name': 'groq/compound-mini', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-5e030150-9eb5-468b-8e7b-e324d4a00439-0' usage_metadata={'input_tokens': 409, 'output_tokens': 188, 'total_tokens': 597}\n"
     ]
    }
   ],
   "source": [
    "# ‚úÖ Step 3: Use Chat Model with Messages\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(model_name=\"groq/compound-mini\")\n",
    "# üîπ Add another human message\n",
    "messages.append(HumanMessage(content=\"I want to learn Python programming language\", name=\"Apoorv\"))\n",
    "# üîπ Invoke LLM with messages\n",
    "response = llm.invoke(messages)\n",
    "print(response)\n",
    "# content='Python is a great language to learn. What do you want to do with Python? Do you want to:\\n\\n1. Build web applications?\\n2. Work with data science and machine learning?\\n3. Automate tasks?\\n4. Create games?\\n\\nKnowing your goals will help me provide more tailored guidance. \\n\\nAlso, are you a complete beginner or do you have some programming experience?' response_metadata={'token_usage': {'completion_tokens': 188, 'prompt_tokens': 409, 'total_tokens': 597, 'completion_time': 0.51895, 'prompt_time': 0.036868, 'queue_time': 0.135441, 'total_time': 0.555818}, 'model_name': 'groq/compound-mini', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-5e030150-9eb5-468b-8e7b-e324d4a00439-0' usage_metadata={'input_tokens': 409, 'output_tokens': 188, 'total_tokens': 597}\n",
    "\n",
    "# üìå LLM reads the full message history and responds to the last message:\n",
    "\"Great choice! Python is a versatile language used in data science, AI, etc.\"\n",
    "# ‚úÖ Step 4: See Metadata of the LLM Response\n",
    "response.response_metadata\n",
    "# {'token_usage': {'completion_tokens': 188,\n",
    "#   'prompt_tokens': 409,\n",
    "#   'total_tokens': 597,\n",
    "#   'completion_time': 0.51895,\n",
    "#   'prompt_time': 0.036868,\n",
    "#   'queue_time': 0.135441,\n",
    "#   'total_time': 0.555818},\n",
    "#  'model_name': 'groq/compound-mini',\n",
    "#  'system_fingerprint': None,\n",
    "#  'finish_reason': 'stop',\n",
    "#  'logprobs': None}\n",
    "\n",
    "\n",
    "# üìä You get:\n",
    "# ‚Ä¢\tTotal tokens used\n",
    "# ‚Ä¢\tLatency\n",
    "# ‚Ä¢\tModel name\n",
    "# ‚Ä¢\tFinish reason\n",
    "# ‚úÖ This helps track costs, performance, and model behavior.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
